\documentclass{article}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

\newcommand{\SAT}{\textnormal{$3$-SAT}}
\newcommand{\SATbf}{\textbf{$3$-SAT}}
\newcommand{\CNF}{\textnormal{$3$-CNF}}
\newcommand{\vbl}[1]{\textnormal{vbl(#1)}}
\newcommand{\dist}[2]{d_H(#1,#2)}
\newcommand{\ball}[2]{B_{#1}(#2)}
\newcommand{\astar}{\alpha^*}
\newcommand{\PBS}{\textnormal{Promise-Ball-$\SAT$}}
\newcommand{\PBSbf}{\textbf{Promise-Ball-$\SATbf$}}
\newcommand{\cc}{\mathcal{C}}
\newcommand{\bits}{\{0,1\}}
\newcommand{\poly}{\textnormal{poly}}
\renewcommand{\Pr}{\textnormal{Pr}}
\renewcommand{\O}{\mathcal{O}^*}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem*{note}{Note}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}


\title{Explanatory Report on Full Derandomization of Sch\"{o}ning's $\SAT$ Algorithm}
\author{}
\date{}

\begin{document}

\maketitle

\section{Introduction}
\paragraph{} The explanatory report is organized in the following manner. In section 2, we introduce some notations and definitions used in this paper. In section 3, we present Sch\"{o}ning's original randomized algorithm\cite{Schoning99} for $\SAT$. In section 4, a derandomization algorithm based on local search by \cite{Dantsin02} is given. In section 5, we present an improvement by \cite{Moser11} that builds on the derandomization algorithm whose performance is arbitrarily close to the randomized version, thereby claiming a full derandomization.

\section{Preliminaries}
\paragraph{} An input instance of a $\SAT$ problem is a $\CNF$(Conjunctive Normal Form) formula $F$ with $n$ variables. $F$ contains a finite set of clauses where each clause $C$ contains at most $3$ pairwise independent literals. A literal $u$ is either a variable $x$ or a complemented variable $\bar{x}$. Let $V$ denote the set of variables in $F$. \par 
A truth assignment $\alpha: V\rightarrow \{0,1\}$ assigns each variable a boolean value. If a literal $u = x$, it is satisfied by $\alpha$ iff $\alpha(x) = 1$. If $u = \bar{x}$, it is satisfied by $\alpha$ iff $\alpha(x) = 0$. A clause $C$ is satisfied by $\alpha$ if at least one of its literals are satisfied by $\alpha$. A formula $F$ is satisfied by $\alpha$ if all clauses are satisfied by $\alpha$. \par 
Given two assignment $\alpha$ and $\beta$, the hamming distance between them $\dist{\alpha}{\beta}$ is defined to be the number of variables $x \in V$ where $\alpha(x) \neq \beta(x)$. A Hamming Ball centered at $\alpha$ with radius $r$ is defined to be $\ball{r}{\alpha} = \{\beta: \dist{\alpha}{\beta} \leq r\}$ that is, all assignments whose hamming distance from $\alpha$ is less or equals to $r$. For assignments of $n$ variables, let $V(r)$ denotes the volume of a Hamming Ball of radius $r$, that is, the number of assignments in the Hamming Ball.\par 
For an assignment $\alpha$ and a literal $l$, we use $\alpha^{[l = 1]}$ to denote the assignment that derives from $\alpha$ after setting $l$ to be $1$. Similarly for a formula $F$, we use $F^{[l = 1]}$ to denote the new formula after setting $l$ to be $1$. \par 
\begin{definition}[\PBS\cite{Moser11}]
	An instance of the $\PBS$ problem $(F,\alpha,r)$ consists of a $\CNF$ formula $F$, an assignment $\alpha$ for $F$ and a natural number $r$. With the promise that the Hamming Ball $\ball{r}{\alpha}$ contains a satisfying assignment for $F$. Find any satisfying assignment.
\end{definition}
The $\PBS$ problem is an important sub-problem for solving $\SAT$. 

\section{Sch\"{o}ning's $3$-SAT Algorithm\cite{Schoning99}}
The randomized algorithm for $\SAT$ builds on a simple random walk algorithm for solving $\PBS$: \par 
\begin{algorithm}[H]
	\caption{$\PBS$-Random-Walk}
	\DontPrintSemicolon
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
	\Input{$(F,\alpha,r)$}
	\Output{A satisfying assignment $\astar$ or NO if no $\astar$ are found}
	\BlankLine
	\For{steps = 1 to 3n}{
		\lIf{$\alpha$ satisfies $F$}{return $\alpha$}
		Choose an arbitrary clause $C$ not satified by $\alpha$\\
		Choose a literal in $C$ uniformly at random and flip its value in $\alpha$
	}
	\lIf{$\alpha$ satisfies $F$}{return $\alpha$}
	\hspace{7em}\lElse{return NO}
\end{algorithm}

\begin{theorem}[\cite{Schoning99}]
For a satisfying assignment $\astar \in \ball{r}{\alpha}$, where $\dist{\alpha}{\astar} = d \leq r$, $\PBS \textnormal{-Random-Walk}$ returns $\astar$ with probability $\geq (\frac{1}{2})^d$.
\end{theorem}
\begin{proof}[Proof Sketch]
	Let $q_d$ be the probability that $\PBS$-Random-Walk returns a satisfying assignment for $F$ given $\dist{\astar}{\alpha} = d$. In each step, with probability $\geq \frac{1}{3}$ the assignment $\alpha$ goes one step closer to $\astar$ and with probability $\leq \frac{2}{3}$ it goes one step further from $\astar$. Hence, $q_d \geq $ the probability that the random walk starting at position $r$ reaches position $0$ within $3n$ steps. Detailed analysis of the random walk gives $q_d \geq (\frac{1}{2})^d$.
\end{proof}

%Do we need this?
\iffalse
\begin{note}
	The input parameter $r$ is not used in $\PBS$\textnormal{-Random-Walk}. By nature of randomness, $\PBS$\textnormal{-Random-Walk} solves $(F,\alpha,d)$ with probability $\geq (\frac{1}{2})^{d}$.
\end{note}
\fi

With $\PBS$-Random-Walk, we have a randomized algorithm for $\SAT$:\par 
\begin{algorithm}[H]
	\caption{Randomized $\SAT$}
	\DontPrintSemicolon
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
	\Input{A $\CNF$ formula $F$ with $n$ variables}
	\Output{A satisfying assignment $\astar$ or NO if no $\astar$ are found}
	\BlankLine
	\For{iterations = 1 to m}{
		Choose a assignment $\alpha$ for $F$ uniformly at random\\
		$\astar$ = $\PBS$-Random-Walk($F,\alpha,n$)\\
		\lIf{$\astar$ satisfies $F$}{return $\astar$}
	}
	{return NO}
\end{algorithm}
\begin{theorem}
	If $F$ is satisfiable, each iteration of the for-loop in \textnormal{Randomized-}$\SAT$ returns a satisfying assignment with probability $\geq (\frac{3}{4})^n$
\end{theorem}
\begin{proof}
	Fix a satisfying assignment $\astar$ for $F$, for the random initial assignment $\alpha$, $\Pr(\dist{\astar}{\alpha}=d) = {n \choose d}{2}^{-n}$. With \textbf{Theorem 1}, we have:
	\begin{align*}
	&\Pr(\textnormal{Success in one iteration}) 
	\geq \sum_{d=0}^{n} {n \choose d} 2^{-n} \cdot \big(\frac{1}{2}\big)^{d} 
	\geq \big(\frac{1}{2}\big)^{n} (1 + \frac{1}{2}) ^n = \big(\frac{3}{4}\big)^{n}
	\end{align*}
\end{proof}
We can then amplify the probability by setting the number of iterations $m = \O((\frac{4}{3})^n)$(we use $\O$ to suppress the polynomial factor in $n$). Each iteration clearly runs in polynomial time and the overall runtime for the randomized algorithm is $\O((\frac{4}{3})^n)$.
\section{Derandomization with Local Search\cite{Dantsin02}}
\paragraph{} Notice that in the randomized algorithm, randomness is used in two parts. One is in $\PBS$-Random-Walk and the other one is to find an assignment $\alpha$ that serves as the center of Hamming Ball $\ball{r}{\alpha}$. Both of them needs to be derandomized. \par 
\subsection{Derandomization of {$\PBSbf$}}
First of all, we derandomize $\PBS$-Random-Walk with a simple recursion algorithm. \par 
\begin{algorithm}[H]
	\caption{$\PBS$-Recursion}
	\DontPrintSemicolon
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
	\Input{$(F,\alpha,r)$}
	\Output{A satisfying assignment $\astar$ or NO if no $\astar$ are found}
	\BlankLine
	\lIf{$\alpha$ satisfies $F$}{return $\alpha$}
	\hspace{7em}\lElseIf{r = 0}{return NO}
	Choose an arbitrary clause $C$ not satified by $\alpha$\\
	\ForEach{literal $l \in C$}{
		$\alpha'$ = $\PBS$-Recursion($F^{[l = 1]}, \alpha^{[l=1]},r-1)$\\
		\lIf {$\alpha'$ satisfies $F$}{Return $\alpha'$}
	}
	{return NO}
\end{algorithm}
\begin{theorem}
	$\PBS \textnormal{-Recursion}$ solves $\PBS$ in $\O(3^r)$ time.
\end{theorem}
\begin{proof}
	The running time is straightforward. Each clause has at most $3$ literals and hence each node in the recursion tree has at most $3$ branches. The depth of the recursion three is at most $r$. Hence, there are at most $3^r$ leaves in the recursion tree. The overall runtime is $\O(3^r)$. \par 
	The correctness can be seen by drawing analogy to the random walk algorithm. Let $\astar$ be the satisfying assignment such that $\dist{\astar}{\alpha} \leq r$. Then there exists a ``lucky" random walk from $\alpha$ to $\astar$ that takes $\leq r$ steps, that is, in each step we move one step closer to $\astar$ and never makes a wrong move. Notice that if we never makes a wrong move, we will never change the assignment of a variable for more than once. \par 
	Now consider the recursion algorithm, in each recursive step we choose a clause $C$ not satisfied by $\alpha$ and we know $C$ is satisfied by $\astar$. Hence, at least one of the literals in $C$ does not comply with $\astar$. Now instead of guessing randomly which is the right literal to flip as in the random walk algorithm, we try all possibilities and at least one of them would be a good move, giving us $\dist{\astar}{\alpha^{[l = 1]}} = r - 1$. Moreover, if we make a good move, we do not need to change the assignment of that literal in the future. We can then assign that value permanently and search using $F^{[l=1]}$ and $\alpha^{[l=1]}$. Hence, this is a depth-first-search algorithm that finds the "lucky" path from $\alpha$ to $\astar$.
\end{proof}

\subsection{Derandomization Using Covering Code}
\paragraph{} Next, we derandomize the choices of initial assignment $\alpha$ with Covering Code. \par 
\begin{definition}[Covering Code]
	A Covering Code of length $n$, $\cc_r \subseteq \bits^n$ is defined as $\forall \alpha \in \bits^n, \exists c \in \cc_r$ such that $\alpha \in \ball{r}{c}$. That is, the Hamming Balls of radius $r$ centered at each member of $\cc_r$ covers the set $\bits^n$.
\end{definition}
\begin{lemma}[Bounding the volume of a Hamming Ball of radius $r$]
	\begin{align*}
	V(r) = \sum_{i = 0}^{n} {n \choose i}
	\end{align*}
	Let $\rho = r/n$. If $0 < \rho \leq 1/2$, then $V(r)$ can be estimated using: [citation needed]
	\begin{align*}
	\frac{1}{\sqrt{8n\rho(1-\rho)}} \cdot 2^{h(\rho)n} \leq V(r) \leq 2^{h(\rho)n}
	\end{align*}
	where $h(\rho) = -\rho \log_2 \rho - (1-\rho)\log_2(1-\rho)$ is the binary entropy function.
\end{lemma}
\begin{theorem}
	There exists a covering code $\cc_r$ of length $n$ and its size $|\cc_r|$ is at most $\lceil n\cdot 2^n / V(r) \rceil$.
\end{theorem}
\begin{proof}
	We give a probabilistic argument. Suppose we choose $ n\cdot 2^n / V(r)$ assignments from $\bits^n$ uniformly and independently to form $\cc_r$. Now fixed an assignment $\alpha$. The probability that $\alpha$ is covered by the Hamming Ball centered at a randomly chosen member $c \in \cc_r$ is exactly $V(r)/2^n$. 
	\begin{align*}
	\Pr(\text{$\alpha$ is not covered}) = \Big(1-\frac{V(r)}{2^n}\Big)^{n\cdot \frac{2^n}{V(r)}} \leq e^{-n}
	\end{align*}
	By taking a union bound, the probability that $\cc_r$ is a covering code $\geq 1 - 2^n\cdot e^{-n} > 0$. Hence, such a covering code exists. 
\end{proof}
Combining \textbf{Lemma 1} and \textbf{Theorem 4}, we have the following corollary:
\begin{corollary}
	Let $0 < \rho \leq 1/2$ and let $\beta(n) = \sqrt{8n\rho(1-\rho)}$. For all $n$, there exists a covering code $\cc$ of length $n$, radius $\rho n$ and size at most $n\beta(n)\cdot 2^{(1-h(\rho))n}$.
\end{corollary}
\begin{theorem}
	A covering code of length $n$ and size at most $n^2\beta(n)\cdot 2^{(1-h(\rho))n}$ can be constructed in $\O(2^{3n})$ time.
\end{theorem}
\begin{proof}
	Notice that constructing a covering code is indeed a set cover problem with $2^n$ sets and $2^n$ elements. There is a well-known greedy algorithm that gives a $\log(m)$-approximation[citation needed] to the set cover problem. In each iteration, we pick the Hamming Ball that covers the largest number of not-yet-covered elements. We can associate each Hamming Ball with the number of not-yet-covered elements that is covers. In each iteration, we pick a Hamming Ball greedily and update the numbers for all remaining Balls. This takes $\poly(n) \cdot 2^n \cdot 2^n = \poly(n) \cdot 2^{2n}$ time. There are at most $2^n$ iterations. Hence, the overall running time is $\O(2^{3n})$. \par 
	From \textbf{Corollary 1}, we know the optimal solution is at most $n\beta(n)\cdot 2^{(1-h(\rho))n}$. The algorithm above gives a $\log(m)$ approximation. Note that the size of the problem $m = 2^n$. Hence, the size of the covering code constructed is at most $\log(2^n) \cdot n\beta(n)\cdot 2^{(1-h(\rho))n} = n^2\beta(n)\cdot 2^{(1-h(\rho))n}$
\end{proof}
%Construction of Covering Code Efficiently
%Overall time
\section{Improving on the Derandomization\cite{Moser11}}
%k(3)-nary Covering Code
%Faster Recursion
%Overall time

\begin{thebibliography}{9}
\bibitem{Dantsin02}
E. Dantsin, A. Goerdt, E. A. Hirsch, R. Kannan, J. Kleinberg, C. Papadimitriou, O. Raghavan, and U. Sch\"{o}ning. 
\textit{A deterministic $(2-2/(k+1))n$ algorithm for k-SAT based on local search.} Theoretical Computer Science 289, (2002).

\bibitem{Moser11}
R. Moser and D. Scheder.
\textit{A Full Derandomization of Sch\"{o}ningâ€™s k-SAT Algorithm.} Proceedings of the 44th Annual ACM Symposium on Theory of Computing, (2011).

\bibitem{Schoning99}
U. Sch\"{o}ning.
\textit{A Probabilistic Algorithm for $k$-SAT and Constraint Satisfaction Problems.} Proceedings of the 40th Annual Symposium on Foundations of Computer Science, (1999).

\end{thebibliography}

\end{document}

